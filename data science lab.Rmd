---
title: "Untitled"
output: html_document
date: "2025-04-01"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load Necessary Libraries
```{r}

library(readr)        # For reading CSV files
library(dplyr)        # Data manipulation
library(tidyr)        # Data tidying and handling missing values
library(tidyverse)    # Collection of R packages including ggplot2, dplyr, tidyr
library(caret)        # For data partitioning and machine learning models
library(glmnet)       # Regularization methods (Ridge, Lasso)
library(ISLR)         # Contains datasets and modeling functions
library(ggplot2)      # For data visualization (optional but useful)
library(stringr)      # For string manipulation (gsub alternatives)
library(forcats)      # For working with categorical variables (factors)
library(purrr)        # Functional programming tools (used in lapply-like functions)
library(reshape2)

```

## Data Cleaning
```{r}
all_car_adverts <- read_csv("all_car_adverts 2.csv", 
col_types = cols(car_price = col_number(), 
car_seller_rating = col_number(), miles = col_number(), year= col_number()))

# Convert PS to BHP where needed (only modify engine_size when the unit is "ps")
all_car_adverts$engine_size <- ifelse(
  all_car_adverts$engine_size_unit == "ps", 
  all_car_adverts$engine_size * 0.98632,  # Convert only PS values
  all_car_adverts$engine_size  # Keep BHP values unchanged
)
all_car_adverts$engine_size_unit[all_car_adverts$engine_size_unit == "ps"] <- "bhp"
all_car_adverts$reg <- gsub(" reg", "", all_car_adverts$reg)

all_car_adverts <- all_car_adverts %>%
  mutate(luxury_level = case_when(
    # Super Luxury (5)
    make %in% c("Aston Martin", "Bentley", "Ferrari", "Lamborghini", "Maserati", "McLaren", "Rolls-Royce") ~ 5,
    
    # Luxury (4)
    make %in% c("Alfa Romeo", "Audi", "BMW", "Cadillac", "Jaguar", "Land Rover", "Lexus", "Mercedes-Benz", "Porsche", "Volvo") ~ 4,
    
    # Upper Mid-range (3)
    make %in% c("Abarth", "Chrysler", "Cupra", "Dodge", "DS AUTOMOBILES", "Infiniti", "Lotus", "MINI", "Morgan", "Peugeot", "Volkswagen") ~ 3,
    
    # Mid-range (2)
    make %in% c("Chevrolet", "Citroen", "Fiat", "Ford", "Honda", "Hummer", "Hyundai", "Jeep", "Kia", "Mazda", "Nissan", "Renault", "SEAT", "SKODA", "Subaru", "Toyota", "Vauxhall") ~ 2,
    
    # Economic (1)
    make %in% c("Aixam", "Austin", "Caterham", "Dacia", "Daewoo", "Daihatsu", "Daimler", "Isuzu", "Lancia", "London Taxis International", "MG", "Mitsubishi", "Perodua", "Proton", "Rover", "Saab", "Smart", "Ssangyong", "Suzuki", "TVR") ~ 1
  ))


all_car_adverts <- all_car_adverts %>% select(-c(car_badges, car_specs, car_attention_grabber,car_sub_title, car_seller, car_seller_location,...1, engine_size_unit, discounted, car_title, reg))
all_car_adverts <- na.omit(all_car_adverts)
all_car_adverts <- all_car_adverts %>%
  rename(fuel_type = feul_type)

# Convert categorical variables to factors
factor_cols <- names(Filter(is.character, all_car_adverts))
all_car_adverts[factor_cols] <- lapply(all_car_adverts[factor_cols], as.factor)

# Handle zero values in `car_price` to prevent log(0) issues
all_car_adverts <- all_car_adverts %>% filter(car_price > 0)

# Apply log transformation to car_price
all_car_adverts <- all_car_adverts %>% mutate(log_price = log(car_price))
```

```{r}
## Eliminating Uncorrelated Variables 

# Select only numeric variables
all_car_adverts_num <- all_car_adverts %>% select_if(is.numeric)

# Compute correlation matrix (numeric variables only)
cor_matrix <- cor(all_car_adverts_num, use = "pairwise.complete.obs")

# Convert correlation matrix into a long format for visualization
cor_melted <- melt(cor_matrix)

# Create heatmap
ggplot(cor_melted, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title = "Correlation Heatmap (Numerical Variables Only)", fill = "Correlation")

```

```{r}

# Remove variables with zero variance (constant values)
all_car_adverts_num <- all_car_adverts_num %>%
  select(where(~ var(.) > 0))  # Keeps only columns with variance

# Compute correlation matrix
cor_matrix <- cor(all_car_adverts_num, use = "pairwise.complete.obs")

# Remove variables that have NA correlations (gray areas)
cor_matrix <- cor_matrix[complete.cases(cor_matrix), complete.cases(cor_matrix)]

# Remove weak correlations (absolute value < 0.1)
cor_filtered <- cor_matrix[abs(cor_matrix["car_price", ]) >= 0.1, abs(cor_matrix["car_price", ]) >= 0.1]

# Convert to long format for visualization
cor_melted <- melt(cor_filtered)

# Create heatmap
ggplot(cor_melted, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title = "Filtered Correlation Heatmap", fill = "Correlation")

```

```{r}
# Drop specified variables from the dataset as they do not contribute much
all_car_adverts <- all_car_adverts %>%
  select(-c(brand_new, first_year_road_tax, full_dealership, part_warranty, part_service, full_service, finance_available))

all_car_adverts <- all_car_adverts %>%
  filter(!body_type %in% c("limousine", "panel van"))

all_car_adverts <- all_car_adverts %>%
  filter(!fuel_type %in% c("bi fuel"))
```


## Drop rarely occuring brands according to their frequency in the dataset
```{r}
# Count occurrences of each brand
brand_counts <- table(all_car_adverts$make)

# Convert to a sorted data frame (descending order)
brand_counts_df <- as.data.frame(brand_counts) %>%
  arrange(desc(Freq))

# Select the top 46 most common brands
top_46_brands <- brand_counts_df$Var1[1:46]

# Filter dataset to keep only these brands
all_car_adverts <- all_car_adverts %>% filter(make %in% top_46_brands)
```


```{r} 
# set the seed to ensure reproducability
set.seed(52)
```

```{r}
# ----------------------------
# Set Aside 10% Holy Test Set
# ----------------------------

# Split dataset: 90% trainable data, 10% final test
holy_test_index <- createDataPartition(all_car_adverts$log_price, p = 0.9, list = FALSE)
trainable_data <- all_car_adverts[holy_test_index, ]  # 90% for modeling
holy_test_data <- all_car_adverts[-holy_test_index, ] # 10% final evaluation set

# ----------------------------
# STEP 2: Sample 35,000 Observations from Trainable Data
# ----------------------------

set.seed(52)  # Ensure reproducibility
sample_index <- sample(nrow(trainable_data), 35000, replace = FALSE)
sample_data <- trainable_data[sample_index, ]  # Use this instead of full 90%

# ----------------------------
# STEP 3: Split Sampled Data into Train/Validation/Test (70/15/15)
# ----------------------------

train_index <- createDataPartition(sample_data$log_price, p = 0.7, list = FALSE)
train_data <- sample_data[train_index, ]
remaining_data <- sample_data[-train_index, ]

val_index <- createDataPartition(remaining_data$log_price, p = 0.5, list = FALSE)
validation_data <- remaining_data[val_index, ]
test_data <- remaining_data[-val_index, ]

```

## Simple Linear Regression with Cross Validation
```{r}
train_val_data <- bind_rows(train_data, validation_data)
# Cross-validation control
cv_control <- trainControl(method = "cv", number = 5)

# ----------------------------
# LOG VERSION
# ----------------------------

# Define formula
excluded_predictors_log <- c("car_price", "log_price", "model", "variant","luxury_level")
predictors_log <- setdiff(names(train_val_data), excluded_predictors_log)
lm_formula_log <- as.formula(paste("log_price ~", paste(predictors_log, collapse = " + ")))

# Cross-validated model
lm_cv_model_log <- train(
  lm_formula_log,
  data = train_val_data,
  method = "lm",
  trControl = cv_control
)

lm_mse_cv_log <- mean(lm_cv_model_log$resample$RMSE^2)
lm_r2_cv_log  <- mean(lm_cv_model_log$resample$Rsquared)

# Fit on full train+val
final_lm_model_log <- lm(lm_formula_log, data = train_val_data)

# Predictions
lm_preds_log_test  <- predict(final_lm_model_log, newdata = test_data)
lm_preds_log_holy  <- predict(final_lm_model_log, newdata = holy_test_data)

# Metrics
lm_mse_test_log  <- mean((test_data$log_price - lm_preds_log_test)^2)
lm_r2_test_log   <- cor(test_data$log_price, lm_preds_log_test)^2

lm_mse_holy_log  <- mean((holy_test_data$log_price - lm_preds_log_holy)^2)
lm_r2_holy_log   <- cor(holy_test_data$log_price, lm_preds_log_holy)^2

```

```{r}
# ----------------------------
# ACTUAL VERSION
# ----------------------------

excluded_predictors_actual <- c("log_price","car_price", "model", "variant","luxury_level")
predictors_actual <- setdiff(names(train_val_data), excluded_predictors_actual)
lm_formula_actual <- as.formula(paste("car_price ~", paste(predictors_actual, collapse = " + ")))

# Cross-validated model
lm_cv_model_actual <- train(
  lm_formula_actual,
  data = train_val_data,
  method = "lm",
  trControl = cv_control
)

lm_mse_cv_actual <- mean(lm_cv_model_actual$resample$RMSE^2)
lm_r2_cv_actual  <- mean(lm_cv_model_actual$resample$Rsquared)

# Fit on full train+val
final_lm_model_actual <- lm(lm_formula_actual, data = train_val_data)

# Predictions
lm_preds_test_actual  <- predict(final_lm_model_actual, newdata = test_data)
lm_preds_holy_actual  <- predict(final_lm_model_actual, newdata = holy_test_data)

# Metrics
lm_mse_test_actual <- mean((test_data$car_price - lm_preds_test_actual)^2)
lm_r2_test_actual  <- cor(test_data$car_price, lm_preds_test_actual)^2

lm_mse_holy_actual <- mean((holy_test_data$car_price - lm_preds_holy_actual)^2)
lm_r2_holy_actual  <- cor(holy_test_data$car_price, lm_preds_holy_actual)^2

```

```{r}
library(knitr)

lm_eval_table <- data.frame(
  Version = rep(c("Log Price", "Actual Price"), each = 3),
  Evaluation = rep(c("Cross-Validation (5-Fold)", "Test Set", "Holy Test Set"), 2),
  MSE = c(lm_mse_cv_log, lm_mse_test_log, lm_mse_holy_log,
          lm_mse_cv_actual, lm_mse_test_actual, lm_mse_holy_actual),
  R2 = c(lm_r2_cv_log, lm_r2_test_log, lm_r2_holy_log,
         lm_r2_cv_actual, lm_r2_test_actual, lm_r2_holy_actual)
)

kable(lm_eval_table, caption = "Linear Regression Performance (MSE and R²) — Log vs Actual, All Evaluation Sets")

```

## Best Subset Selection with Cross Validation

```{r}
# LOG PRICE VERSION - Best Subset Selection

# Step 4
target_bss_log <- "log_price"
excluded_bss_log <- c("car_price", "log_price", "model", "variant", "luxury_level")
predictors_bss_log <- setdiff(names(train_data), excluded_bss_log)

# Step 5: Generate formulas
generate_formulas <- function(p, x_vars, y_var) {
  apply(combn(x_vars, p), 2, function(vars) {
    paste0(y_var, " ~ ", paste(vars, collapse = " + "))
  })
}

predictor_range <- 3:10  # We adjusted this to balance speed and performance

# Step 6: Evaluate formulas using CV
evaluate_formula_cv <- function(formula_str, dataset, k = 5) {
  formula_obj <- as.formula(formula_str)
  folds <- sample(rep(1:k, length.out = nrow(dataset)))
  dataset <- dataset %>% mutate(folds = folds)

  mses <- numeric(k)
  r2s <- numeric(k)

  for (i in 1:k) {
    train_fold <- dataset %>% filter(folds != i)
    valid_fold <- dataset %>% filter(folds == i)

    factor_cols <- names(Filter(is.factor, train_fold))
    valid_fold <- valid_fold %>%
      mutate(across(all_of(factor_cols), ~ factor(.x, levels = levels(train_fold[[cur_column()]]))))

    model <- lm(formula_obj, data = train_fold)
    preds <- predict(model, newdata = valid_fold)
    actual <- valid_fold[[as.character(formula_obj)[2]]]

    mses[i] <- mean((actual - preds)^2)
    r2s[i] <- cor(actual, preds)^2
  }

  list(mean_mse = mean(mses), mean_r2 = mean(r2s))
}

# Step 7
bss_results_log <- data.frame(
  predictors_count = integer(),
  formula = character(),
  cv_mse = numeric(),
  cv_r2 = numeric(),
  stringsAsFactors = FALSE
)

for (p in predictor_range) {
  formulas <- generate_formulas(p, predictors_bss_log, target_bss_log)
  for (f in formulas) {
    metrics <- evaluate_formula_cv(f, train_data)
    bss_results_log <- rbind(bss_results_log, data.frame(
      predictors_count = p,
      formula = f,
      cv_mse = metrics$mean_mse,
      cv_r2 = metrics$mean_r2
    ))
  }
}

# Step 8: Select best formula
bss_results_log <- bss_results_log %>%
  mutate(score = 0.475 * (cv_mse / max(cv_mse)) +
                 0.475 * (1 - (cv_r2 / max(cv_r2))) +
                 0.05 * (predictors_count / max(predictors_count)))

best_formula_bss_log <- as.formula(bss_results_log$formula[which.min(bss_results_log$score)])

# Step 9: Fit on train+validation
train_val_data <- bind_rows(train_data, validation_data)
model_bss_log <- lm(best_formula_bss_log, data = train_val_data)

# Step 10: Test set
pred_bss_log_test <- predict(model_bss_log, newdata = test_data)
mse_bss_test_log <- mean((test_data$log_price - pred_bss_log_test)^2)
r2_bss_test_log <- cor(test_data$log_price, pred_bss_log_test)^2

# Step 11: Holy test set
pred_bss_log_holy <- predict(model_bss_log, newdata = holy_test_data)
mse_bss_holy_log <- mean((holy_test_data$log_price - pred_bss_log_holy)^2)
r2_bss_holy_log <- cor(holy_test_data$log_price, pred_bss_log_holy)^2

# CV results
mse_bss_cv_log <- min(bss_results_log$cv_mse)
r2_bss_cv_log <- bss_results_log$cv_r2[which.min(bss_results_log$score)]

```

```{r}
# ACTUAL PRICE VERSION - Best Subset Selection

target_bss_actual <- "car_price"
excluded_bss_actual <- c("log_price","car_price", "model", "variant", "reg")
predictors_bss_actual <- setdiff(names(train_data), excluded_bss_actual)

bss_results_actual <- data.frame(
  predictors_count = integer(),
  formula = character(),
  cv_mse = numeric(),
  cv_r2 = numeric(),
  stringsAsFactors = FALSE
)

for (p in predictor_range) {
  formulas <- generate_formulas(p, predictors_bss_actual, target_bss_actual)
  for (f in formulas) {
    metrics <- evaluate_formula_cv(f, train_data)
    bss_results_actual <- rbind(bss_results_actual, data.frame(
      predictors_count = p,
      formula = f,
      cv_mse = metrics$mean_mse,
      cv_r2 = metrics$mean_r2
    ))
  }
}

bss_results_actual <- bss_results_actual %>%
  mutate(score = 0.475 * (cv_mse / max(cv_mse)) +
                 0.475 * (1 - (cv_r2 / max(cv_r2))) +
                 0.05 * (predictors_count / max(predictors_count)))

best_formula_bss_actual <- as.formula(bss_results_actual$formula[which.min(bss_results_actual$score)])
model_bss_actual <- lm(best_formula_bss_actual, data = train_val_data)

pred_bss_actual_test <- predict(model_bss_actual, newdata = test_data)
mse_bss_test_actual <- mean((test_data$car_price - pred_bss_actual_test)^2)
r2_bss_test_actual <- cor(test_data$car_price, pred_bss_actual_test)^2

pred_bss_actual_holy <- predict(model_bss_actual, newdata = holy_test_data)
mse_bss_holy_actual <- mean((holy_test_data$car_price - pred_bss_actual_holy)^2)
r2_bss_holy_actual <- cor(holy_test_data$car_price, pred_bss_actual_holy)^2

mse_bss_cv_actual <- min(bss_results_actual$cv_mse)
r2_bss_cv_actual <- bss_results_actual$cv_r2[which.min(bss_results_actual$score)]

```

```{r}
bss_summary_table <- data.frame(
  Version = rep(c("Log Price", "Actual Price"), each = 3),
  Evaluation = rep(c("Cross-Validation (5-Fold)", "Test Set", "Holy Test Set"), 2),
  MSE = c(mse_bss_cv_log, mse_bss_test_log, mse_bss_holy_log,
          mse_bss_cv_actual, mse_bss_test_actual, mse_bss_holy_actual),
  R2 = c(r2_bss_cv_log, r2_bss_test_log, r2_bss_holy_log,
         r2_bss_cv_actual, r2_bss_test_actual, r2_bss_holy_actual)
)

kable(bss_summary_table, caption = "Best Subset Selection Performance (MSE and R²) — Log vs Actual")

```
## Lasso with Cross Validated Lambda
```{r}
library(glmnet)

# Combine training and validation sets
train_val_data <- bind_rows(train_data, validation_data)

# Prepare matrices for log version
X_lasso_log_train <- model.matrix(log_price ~ . -1, data = train_val_data)
Y_lasso_log_train <- train_val_data$log_price

X_lasso_log_test <- model.matrix(log_price ~ . -1, data = test_data)
Y_lasso_log_test <- test_data$log_price

# Cross-validation
set.seed(52)
cv_lasso_log <- cv.glmnet(X_lasso_log_train, Y_lasso_log_train, alpha = 1, nfolds = 5)
best_lambda_lasso_log <- cv_lasso_log$lambda.min

# Final model using best lambda
model_lasso_log <- glmnet(X_lasso_log_train, Y_lasso_log_train, alpha = 1, lambda = best_lambda_lasso_log)

# Test set predictions
pred_lasso_log_test <- predict(model_lasso_log, newx = X_lasso_log_test)
mse_lasso_test_log <- mean((Y_lasso_log_test - pred_lasso_log_test)^2)
r2_lasso_test_log <- cor(Y_lasso_log_test, pred_lasso_log_test)^2

# Holy test set
X_lasso_log_holy <- model.matrix(log_price ~ . -1, data = holy_test_data)
Y_lasso_log_holy <- holy_test_data$log_price

pred_lasso_log_holy <- predict(model_lasso_log, newx = X_lasso_log_holy)
mse_lasso_holy_log <- mean((Y_lasso_log_holy - pred_lasso_log_holy)^2)
r2_lasso_holy_log <- cor(Y_lasso_log_holy, pred_lasso_log_holy)^2

# Cross-Validation performance
mse_lasso_cv_log <- min(cv_lasso_log$cvm)
r2_lasso_cv_log <- 1 - cv_lasso_log$cvm[cv_lasso_log$lambda == best_lambda_lasso_log] / var(Y_lasso_log_train)

```

```{r}
# Prepare matrices for actual version
X_lasso_actual_train <- model.matrix(car_price ~ . -1, data = train_val_data)
Y_lasso_actual_train <- train_val_data$car_price

X_lasso_actual_test <- model.matrix(car_price ~ . -1, data = test_data)
Y_lasso_actual_test <- test_data$car_price

# Cross-validation
set.seed(52)
cv_lasso_actual <- cv.glmnet(X_lasso_actual_train, Y_lasso_actual_train, alpha = 1, nfolds = 5)
best_lambda_lasso_actual <- cv_lasso_actual$lambda.min

# Final model
model_lasso_actual <- glmnet(X_lasso_actual_train, Y_lasso_actual_train, alpha = 1, lambda = best_lambda_lasso_actual)

# Test predictions
pred_lasso_actual_test <- predict(model_lasso_actual, newx = X_lasso_actual_test)
mse_lasso_test_actual <- mean((Y_lasso_actual_test - pred_lasso_actual_test)^2)
r2_lasso_test_actual <- cor(Y_lasso_actual_test, pred_lasso_actual_test)^2

# Holy test set
X_lasso_actual_holy <- model.matrix(car_price ~ . -1, data = holy_test_data)
Y_lasso_actual_holy <- holy_test_data$car_price

pred_lasso_actual_holy <- predict(model_lasso_actual, newx = X_lasso_actual_holy)
mse_lasso_holy_actual <- mean((Y_lasso_actual_holy - pred_lasso_actual_holy)^2)
r2_lasso_holy_actual <- cor(Y_lasso_actual_holy, pred_lasso_actual_holy)^2

# Cross-validation
mse_lasso_cv_actual <- min(cv_lasso_actual$cvm)
r2_lasso_cv_actual <- 1 - cv_lasso_actual$cvm[cv_lasso_actual$lambda == best_lambda_lasso_actual] / var(Y_lasso_actual_train)

```

```{r}
library(knitr)

lasso_table <- data.frame(
  Version = rep(c("Log Price", "Actual Price"), each = 3),
  Evaluation = rep(c("Cross-Validation (5-Fold)", "Test Set", "Holy Test Set"), 2),
  MSE = c(mse_lasso_cv_log, mse_lasso_test_log, mse_lasso_holy_log,
          mse_lasso_cv_actual, mse_lasso_test_actual, mse_lasso_holy_actual),
  R2 = c(r2_lasso_cv_log, r2_lasso_test_log, r2_lasso_holy_log,
         r2_lasso_cv_actual, r2_lasso_test_actual, r2_lasso_holy_actual)
)

kable(lasso_table, caption = "Lasso Regression Performance (MSE and R²) — Log vs Actual")

```

## Ridge with Cross Validation
```{r}
# Prepare matrices
X_ridge_log_train <- model.matrix(log_price ~ . -1, data = train_val_data)
Y_ridge_log_train <- train_val_data$log_price

X_ridge_log_test <- model.matrix(log_price ~ . -1, data = test_data)
Y_ridge_log_test <- test_data$log_price

# Cross-validation
set.seed(52)
cv_ridge_log <- cv.glmnet(X_ridge_log_train, Y_ridge_log_train, alpha = 0, nfolds = 5)
best_lambda_ridge_log <- cv_ridge_log$lambda.min

# Final model
model_ridge_log <- glmnet(X_ridge_log_train, Y_ridge_log_train, alpha = 0, lambda = best_lambda_ridge_log)

# Test set
pred_ridge_log_test <- predict(model_ridge_log, newx = X_ridge_log_test)
mse_ridge_test_log <- mean((Y_ridge_log_test - pred_ridge_log_test)^2)
r2_ridge_test_log <- cor(Y_ridge_log_test, pred_ridge_log_test)^2

# Holy test set
X_ridge_log_holy <- model.matrix(log_price ~ . -1, data = holy_test_data)
Y_ridge_log_holy <- holy_test_data$log_price

pred_ridge_log_holy <- predict(model_ridge_log, newx = X_ridge_log_holy)
mse_ridge_holy_log <- mean((Y_ridge_log_holy - pred_ridge_log_holy)^2)
r2_ridge_holy_log <- cor(Y_ridge_log_holy, pred_ridge_log_holy)^2

# CV performance
mse_ridge_cv_log <- min(cv_ridge_log$cvm)
r2_ridge_cv_log <- 1 - cv_ridge_log$cvm[cv_ridge_log$lambda == best_lambda_ridge_log] / var(Y_ridge_log_train)

```

```{r}
# Prepare matrices
X_ridge_actual_train <- model.matrix(car_price ~ . -1, data = train_val_data)
Y_ridge_actual_train <- train_val_data$car_price

X_ridge_actual_test <- model.matrix(car_price ~ . -1, data = test_data)
Y_ridge_actual_test <- test_data$car_price

# Cross-validation
set.seed(52)
cv_ridge_actual <- cv.glmnet(X_ridge_actual_train, Y_ridge_actual_train, alpha = 0, nfolds = 5)
best_lambda_ridge_actual <- cv_ridge_actual$lambda.min

# Final model
model_ridge_actual <- glmnet(X_ridge_actual_train, Y_ridge_actual_train, alpha = 0, lambda = best_lambda_ridge_actual)

# Test set
pred_ridge_actual_test <- predict(model_ridge_actual, newx = X_ridge_actual_test)
mse_ridge_test_actual <- mean((Y_ridge_actual_test - pred_ridge_actual_test)^2)
r2_ridge_test_actual <- cor(Y_ridge_actual_test, pred_ridge_actual_test)^2

# Holy test set
X_ridge_actual_holy <- model.matrix(car_price ~ . -1, data = holy_test_data)
Y_ridge_actual_holy <- holy_test_data$car_price

pred_ridge_actual_holy <- predict(model_ridge_actual, newx = X_ridge_actual_holy)
mse_ridge_holy_actual <- mean((Y_ridge_actual_holy - pred_ridge_actual_holy)^2)
r2_ridge_holy_actual <- cor(Y_ridge_actual_holy, pred_ridge_actual_holy)^2

# CV performance
mse_ridge_cv_actual <- min(cv_ridge_actual$cvm)
r2_ridge_cv_actual <- 1 - cv_ridge_actual$cvm[cv_ridge_actual$lambda == best_lambda_ridge_actual] / var(Y_ridge_actual_train)

```

```{r}
library(knitr)

ridge_table <- data.frame(
  Version = rep(c("Log Price", "Actual Price"), each = 3),
  Evaluation = rep(c("Cross-Validation (5-Fold)", "Test Set", "Holy Test Set"), 2),
  MSE = c(mse_ridge_cv_log, mse_ridge_test_log, mse_ridge_holy_log,
          mse_ridge_cv_actual, mse_ridge_test_actual, mse_ridge_holy_actual),
  R2 = c(r2_ridge_cv_log, r2_ridge_test_log, r2_ridge_holy_log,
         r2_ridge_cv_actual, r2_ridge_test_actual, r2_ridge_holy_actual)
)

kable(ridge_table, caption = "Ridge Regression Performance (MSE and R²) — Log vs Actual")

```

```{r}
cv_log_results <- data.frame(
  Model = c("Linear", "Best Subset", "Lasso", "Ridge"),
  MSE = c(lm_mse_cv_log, mse_bss_cv_log, mse_lasso_cv_log, mse_ridge_cv_log),
  R2  = c(lm_r2_cv_log, r2_bss_cv_log, r2_lasso_cv_log, r2_ridge_cv_log)
)

# MSE Bar Chart
ggplot(cv_log_results, aes(x = Model, y = MSE, fill = Model)) +
  geom_bar(stat = "identity") +
  labs(title = "Cross-Validated MSE (Log Price)", y = "MSE") +
  theme_minimal() +
  theme(legend.position = "none")

# R² Bar Chart
ggplot(cv_log_results, aes(x = Model, y = R2, fill = Model)) +
  geom_bar(stat = "identity") +
  labs(title = "Cross-Validated R² (Log Price)", y = "R²") +
  theme_minimal() +
  theme(legend.position = "none")


```
```{r}
cv_actual_results <- data.frame(
  Model = c("Linear", "Best Subset", "Lasso", "Ridge"),
  MSE = c(lm_mse_cv_actual, mse_bss_cv_actual, mse_lasso_cv_actual, mse_ridge_cv_actual),
  R2  = c(lm_r2_cv_actual, r2_bss_cv_actual, r2_lasso_cv_actual, r2_ridge_cv_actual)
)

# MSE Bar Chart
ggplot(cv_actual_results, aes(x = Model, y = MSE, fill = Model)) +
  geom_bar(stat = "identity") +
  labs(title = "Cross-Validated MSE (Actual Price)", y = "MSE") +
  theme_minimal() +
  theme(legend.position = "none")

# R² Bar Chart
ggplot(cv_actual_results, aes(x = Model, y = R2, fill = Model)) +
  geom_bar(stat = "identity") +
  labs(title = "Cross-Validated R² (Actual Price)", y = "R²") +
  theme_minimal() +
  theme(legend.position = "none")

```
```{r}
# Log Price version: Actual vs Predicted
log_scatter_df <- data.frame(
  Actual = holy_test_data$log_price,
  Linear = lm_preds_log_holy,
  BestSubset = pred_bss_log_holy,
  Lasso = as.numeric(pred_lasso_log_holy),
  Ridge = as.numeric(pred_ridge_log_holy)
)

# Actual Price version: Actual vs Predicted
actual_scatter_df <- data.frame(
  Actual = holy_test_data$car_price,
  Linear = lm_preds_holy_actual,
  BestSubset = pred_bss_actual_holy,
  Lasso = as.numeric(pred_lasso_actual_holy),
  Ridge = as.numeric(pred_ridge_actual_holy)
)

```


```{r}
library(ggplot2)
library(gridExtra)

plot_scatter <- function(df, pred_col, title, color) {
  ggplot(df, aes(x = Actual, y = .data[[pred_col]])) +
    geom_point(alpha = 0.4, color = color) +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
    labs(title = title, x = "Actual", y = "Predicted") +
    theme_minimal()
}

```

```{r}
p_log_lin <- plot_scatter(log_scatter_df, "Linear", "Linear - Log", "blue")
p_log_bss <- plot_scatter(log_scatter_df, "BestSubset", "Best Subset - Log", "red")
p_log_lasso <- plot_scatter(log_scatter_df, "Lasso", "Lasso - Log", "green")
p_log_ridge <- plot_scatter(log_scatter_df, "Ridge", "Ridge - Log", "purple")

```

```{r}
p_act_lin <- plot_scatter(actual_scatter_df, "Linear", "Linear - Actual", "blue")
p_act_bss <- plot_scatter(actual_scatter_df, "BestSubset", "Best Subset - Actual", "red")
p_act_lasso <- plot_scatter(actual_scatter_df, "Lasso", "Lasso - Actual", "green")
p_act_ridge <- plot_scatter(actual_scatter_df, "Ridge", "Ridge - Actual", "purple")

```

```{r}
grid.arrange(p_log_lin, p_log_bss, p_log_lasso, p_log_ridge, 
             ncol = 2, 
             top = "Predicted vs Actual (Log Price) — All Models")

```

```{r}
grid.arrange(p_act_lin, p_act_bss, p_act_lasso, p_act_ridge, 
             ncol = 2, 
             top = "Predicted vs Actual (Actual Price) — All Models")

```
```{r}
library(tidyr)
library(ggplot2)

# Prepare values
model_eval_df <- data.frame(
  Model = c("Linear", "Best Subset", "Lasso", "Ridge"),
  RMSE = c(
    sqrt(lm_mse_holy_actual),
    sqrt(mse_bss_holy_actual),
    sqrt(mse_lasso_holy_actual),
    sqrt(mse_ridge_holy_actual)
  ),
  R2 = c(
    lm_r2_holy_actual,
    r2_bss_holy_actual,
    r2_lasso_holy_actual,
    r2_ridge_holy_actual
  )
)

# Scale R2 to match RMSE range (so they’re both visible)
rmse_range <- range(model_eval_df$RMSE)
r2_range <- range(model_eval_df$R2)
scaling_factor <- diff(rmse_range) / diff(r2_range)

model_eval_df$R2_scaled <- (model_eval_df$R2 - min(model_eval_df$R2)) * scaling_factor + min(model_eval_df$RMSE)

# Reshape to long format
plot_data <- model_eval_df %>%
  select(Model, RMSE, R2_scaled) %>%
  rename(R2 = R2_scaled) %>%
  pivot_longer(cols = c(RMSE, R2), names_to = "Metric", values_to = "Value")

# Plot
ggplot(plot_data, aes(x = Model, y = Value, fill = Metric)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.7)) +
  scale_fill_manual(values = c("skyblue", "tomato")) +
  labs(
    title = "Holy Test Set Performance (Actual Price)",
    y = "Scaled Metric Value",
    x = "Model"
  ) +
  theme_minimal() +
  theme(
    legend.position = "top",
    plot.title = element_text(face = "bold", hjust = 0.5)
  )


```

```{r}
# Compute RMSE and prepare values
model_eval_df <- data.frame(
  Model = c("Linear", "Best Subset", "Lasso", "Ridge"),
  RMSE = c(
    sqrt(lm_mse_holy_actual),
    sqrt(mse_bss_holy_actual),
    sqrt(mse_lasso_holy_actual),
    sqrt(mse_ridge_holy_actual)
  ),
  R2 = c(
    lm_r2_holy_actual,
    r2_bss_holy_actual,
    r2_lasso_holy_actual,
    r2_ridge_holy_actual
  )
)

# Scale R² to RMSE range
range_rmse <- range(model_eval_df$RMSE)
range_r2 <- range(model_eval_df$R2)
scale_factor <- diff(range_rmse) / diff(range_r2)

model_eval_df$R2_scaled <- (model_eval_df$R2 - min(model_eval_df$R2)) * scale_factor + min(model_eval_df$RMSE)

# Plot with both bars
ggplot(model_eval_df, aes(x = Model)) +
  geom_bar(aes(y = RMSE, fill = "RMSE"), stat = "identity", position = "dodge", width = 0.35) +
  geom_bar(aes(y = R2_scaled, fill = "R²"), stat = "identity", position = position_nudge(x = 0.35), width = 0.35) +
  scale_fill_manual(values = c("RMSE" = "skyblue", "R²" = "tomato")) +
  scale_y_continuous(
    name = "RMSE",
    sec.axis = sec_axis(~ (. - min(model_eval_df$RMSE)) / scale_factor + min(model_eval_df$R2),
                        name = "R²")
  ) +
  labs(title = "Holy Test Set Performance (Actual Price)", x = "Model", fill = "") +
  theme_minimal() +
  theme(
    axis.title.y.left = element_text(color = "skyblue4"),
    axis.text.y.left = element_text(color = "skyblue4"),
    axis.title.y.right = element_text(color = "tomato4"),
    axis.text.y.right = element_text(color = "tomato4"),
    legend.position = "top",
    plot.title = element_text(face = "bold", hjust = 0.5)
  )

```

```{r}
ggplot(plot_df, aes(x = Model, y = Value, fill = Metric)) +
  geom_bar(stat = "identity", 
           position = position_dodge(width = 0.75), 
           width = 0.55) +
  scale_fill_manual(values = c("skyblue", "tomato"), labels = c("RMSE", "R²")) +
  scale_y_continuous(
    name = "RMSE",
    sec.axis = sec_axis(~ (. - min(model_eval_df$RMSE)) / scale_factor + min(model_eval_df$R2),
                        name = "R²")
  ) +
  labs(
    title = "Holy Test Set Performance Comparison (Actual Price)",
    x = "Model",
    fill = ""
  ) +
  theme_minimal() +
  theme(
    axis.title.y.left = element_text(color = "black"),
    axis.text.y.left = element_text(color = "black"),
    axis.title.y.right = element_text(color = "black"),
    axis.text.y.right = element_text(color = "black"),
    legend.position = "top",
    plot.title = element_text(face = "bold", hjust = 0.5)
  )

```


```{r}
# Load required lib
library(ggplot2)
library(dplyr)

# Separate plots per luxury level
luxury_levels <- sort(unique(residual_summary$luxury_level))

# Loop over each luxury level and create a plot
for (lvl in luxury_levels) {
  data_subset <- residual_summary %>%
    filter(luxury_level == lvl) %>%
    arrange(desc(mean_abs_pct_residual)) %>%
    mutate(make = factor(make, levels = make))  # preserve order

  p <- ggplot(data_subset, aes(x = make, y = mean_abs_pct_residual, fill = make)) +
    geom_bar(stat = "identity") +
    scale_fill_viridis_d(option = "C", begin = 0.1, end = 0.9) +  # colorful but aesthetic
    labs(
      title = paste("Luxury Level", lvl, "- Mean Abs. % Residuals by Brand"),
      x = "Car Brand",
      y = "Mean Absolute Percentage Residual",
      fill = "Brand"
    ) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1, size = 9),
      plot.title = element_text(face = "bold", hjust = 0.5),
      legend.position = "none"
    )

  print(p)  # display the plot
}

```

```{r}
library(dplyr)
library(ggplot2)

# --- STEP 1: Predict and compute % residuals (signed) ---
holy_test_data$predicted_lasso <- as.numeric(pred_lasso_actual_holy)
holy_test_data$pct_residual <- (holy_test_data$car_price - holy_test_data$predicted_lasso) / holy_test_data$car_price

# --- STEP 2: Aggregate mean % residuals by brand & luxury level ---
residual_summary <- holy_test_data %>%
  group_by(luxury_level, make) %>%
  summarise(mean_pct_residual = mean(pct_residual, na.rm = TRUE)) %>%
  arrange(luxury_level, desc(mean_pct_residual))

# --- STEP 3: Generate one plot per luxury level ---
luxury_levels <- sort(unique(residual_summary$luxury_level))

for (lvl in luxury_levels) {
  data_subset <- residual_summary %>%
    filter(luxury_level == lvl) %>%
    arrange(desc(mean_pct_residual)) %>%
    mutate(make = factor(make, levels = make))

  p <- ggplot(data_subset, aes(x = make, y = mean_pct_residual, fill = make)) +
    geom_bar(stat = "identity") +
    geom_hline(yintercept = 0, linetype = "dashed", color = "gray40") +
    scale_fill_viridis_d(option = "C", begin = 0.1, end = 0.9) +
    labs(
      title = paste("Luxury Level", lvl, "- Mean Percentage Residuals by Brand"),
      x = "Car Brand",
      y = "Mean Percentage Residual",
      fill = "Brand"
    ) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1, size = 9),
      plot.title = element_text(face = "bold", hjust = 0.5),
      legend.position = "none"
    )

  print(p)
}

```
```{r}
# Group by brand and compute mean signed percentage residual
brand_bias_summary <- holy_test_data %>%
  group_by(make) %>%
  summarise(mean_pct_residual = mean(pct_residual, na.rm = TRUE),
            n = n()) %>%
  arrange(mean_pct_residual)

# Optional: filter out brands with too few observations
brand_bias_summary <- brand_bias_summary %>% filter(n >= 5)

# Top 5 overpredicted (most negative)
top5_overpredicted <- head(brand_bias_summary, 5)

# Top 5 underpredicted (most positive)
top5_underpredicted <- tail(brand_bias_summary, 5)

# Display
library(knitr)
kable(top5_overpredicted, caption = "🔻 Top 5 Overpredicted Brands (Model Predicts Too High)")
kable(top5_underpredicted[order(-top5_underpredicted$mean_pct_residual), ], 
      caption = "🔺 Top 5 Underpredicted Brands (Model Predicts Too Low)")

```


```{r}
library(dplyr)
library(ggplot2)

# Step 1: Calculate signed percentage residuals
holy_test_data$predicted_lasso <- as.numeric(pred_lasso_actual_holy)
holy_test_data$pct_residual <- (holy_test_data$car_price - holy_test_data$predicted_lasso) / holy_test_data$car_price

# Step 2: Group summary
residual_summary <- holy_test_data %>%
  group_by(luxury_level, make) %>%
  summarise(
    mean_pct_residual = mean(pct_residual, na.rm = TRUE),
    brand_count = n()
  ) %>%
  arrange(luxury_level, desc(mean_pct_residual))

# Step 3: Loop over all luxury levels and plot
luxury_levels <- sort(unique(residual_summary$luxury_level))

for (lvl in luxury_levels) {
  data_subset <- residual_summary %>%
    filter(luxury_level == lvl) %>%
    arrange(desc(mean_pct_residual)) %>%
    mutate(make = factor(make, levels = make))

  # Match scales between residuals and counts
  max_left <- max(abs(data_subset$mean_pct_residual), na.rm = TRUE)
  max_right <- max(data_subset$brand_count, na.rm = TRUE)
  scale_factor <- max_left / max_right

  p <- ggplot(data_subset, aes(x = make)) +
    # Mean percentage residual bars
    geom_bar(aes(y = mean_pct_residual, fill = make), stat = "identity") +

    # Brand count as black line (scaled, non-negative)
    geom_segment(aes(
      x = make, xend = make,
      y = 0,
      yend = pmax(0, brand_count * scale_factor)
    ), color = "black", linewidth = 0.8) +

    # Horizontal zero line
    geom_hline(yintercept = 0, linetype = "dashed", color = "gray40") +
    geom_hline(yintercept = 0.15, linetype = "dotted", color = "red", linewidth = 0.7) +
    geom_hline(yintercept = -0.15, linetype = "dotted", color = "red", linewidth = 0.7) +

    # Left: Residuals / Right: Brand Count
    scale_y_continuous(
      name = "Mean Percentage Residual",
      sec.axis = sec_axis(
        trans = ~ . / scale_factor,
        name = "Brand Count",
        breaks = pretty(c(0, max_right))
      )
    ) +

    # Colors and titles
    scale_fill_viridis_d(option = "C", begin = 0.1, end = 0.9) +
    labs(
      title = paste("Luxury Level", lvl, "- Residual Bias (Bars) + Brand Count (Black Line)"),
      x = "Car Brand"
    ) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1, size = 9),
      plot.title = element_text(face = "bold", hjust = 0.5),
      axis.title.y.left = element_text(color = "steelblue4"),
      axis.title.y.right = element_text(color = "black"),
      legend.position = "none"
    )

  print(p)
}

```



---
title: "newdraft"
output: html_document
date: "2025-02-24"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(readr)        # For reading CSV files
library(dplyr)        # Data manipulation
library(tidyr)        # Data tidying and handling missing values
library(tidyverse)    # Collection of R packages including ggplot2, dplyr, tidyr
library(caret)        # For data partitioning and machine learning models
library(glmnet)       # Regularization methods (Ridge, Lasso)
library(ISLR)         # Contains datasets and modeling functions
library(ggplot2)      # For data visualization (optional but useful)
library(stringr)      # For string manipulation (gsub alternatives)
library(forcats)      # For working with categorical variables (factors)
library(purrr)        # Functional programming tools (used in lapply-like functions)
```


## Cleaning the Data

```{r message=FALSE, warning=FALSE}

all_car_adverts <- read_csv("all_car_adverts 2.csv", 
col_types = cols(car_price = col_number(), 
car_seller_rating = col_number(), miles = col_number(), year= col_number()))

# Convert PS to BHP where needed (only modify engine_size when the unit is "ps")
all_car_adverts$engine_size <- ifelse(
  all_car_adverts$engine_size_unit == "ps", 
  all_car_adverts$engine_size * 0.98632,  # Convert only PS values
  all_car_adverts$engine_size  # Keep BHP values unchanged
)
all_car_adverts$engine_size_unit[all_car_adverts$engine_size_unit == "ps"] <- "bhp"
all_car_adverts$reg <- gsub(" reg", "", all_car_adverts$reg)

all_car_adverts <- all_car_adverts %>%
  mutate(luxury_level = case_when(
    # Super Luxury (5)
    make %in% c("Aston Martin", "Bentley", "Ferrari", "Lamborghini", "Maserati", "McLaren", "Rolls-Royce") ~ 5,
    
    # Luxury (4)
    make %in% c("Alfa Romeo", "Audi", "BMW", "Cadillac", "Jaguar", "Land Rover", "Lexus", "Mercedes-Benz", "Porsche", "Volvo") ~ 4,
    
    # Upper Mid-range (3)
    make %in% c("Abarth", "Chrysler", "Cupra", "Dodge", "DS AUTOMOBILES", "Infiniti", "Lotus", "MINI", "Morgan", "Peugeot", "Volkswagen") ~ 3,
    
    # Mid-range (2)
    make %in% c("Chevrolet", "Citroen", "Fiat", "Ford", "Honda", "Hummer", "Hyundai", "Jeep", "Kia", "Mazda", "Nissan", "Renault", "SEAT", "SKODA", "Subaru", "Toyota", "Vauxhall") ~ 2,
    
    # Economic (1)
    make %in% c("Aixam", "Austin", "Caterham", "Dacia", "Daewoo", "Daihatsu", "Daimler", "Isuzu", "Lancia", "London Taxis International", "MG", "Mitsubishi", "Perodua", "Proton", "Rover", "Saab", "Smart", "Ssangyong", "Suzuki", "TVR") ~ 1
  ))



all_car_adverts <- all_car_adverts %>% select(-c(car_badges, car_specs, car_attention_grabber,car_sub_title, car_seller, car_seller_location,...1, engine_size_unit, discounted, brand_new,first_year_road_tax,full_dealership,part_warranty, part_service,full_service,ulez, car_title))
all_car_adverts <- na.omit(all_car_adverts)
all_car_adverts <- all_car_adverts %>%
  rename(fuel_type = feul_type)

# Convert categorical variables to factors
factor_cols <- names(Filter(is.character, all_car_adverts))
all_car_adverts[factor_cols] <- lapply(all_car_adverts[factor_cols], as.factor)

# Handle zero values in `car_price` to prevent log(0) issues
all_car_adverts <- all_car_adverts %>% filter(car_price > 0)

# Apply log transformation to car_price
all_car_adverts <- all_car_adverts %>% mutate(log_price = log(car_price))
```

## Classification using AI:
# Prompt:
Classify the following car brands into five luxury levels from 1 (Economic) to 5 (Super Luxury).

The classification should always be consistent with the given reference.
Use the following criteria:
5 - Super Luxury: Exclusive luxury and exotic brands (ultra-high price, exclusivity).
4 - Luxury: Premium brands offering high-end luxury models.
3 - Upper Mid-range: Brands with some luxury or premium models.
2 - Mid-range: Popular mainstream brands with mass-market appeal.
1 - Economic: Entry-level or budget-friendly manufacturers.

Instructions:

If a brand is not listed, classify it by similarity to listed brands, but prioritize sticking to the above reference.
Output the classification as a table with two columns: Brand and Luxury Level (1-5).
Ensure reproducibility by not altering the categories in future runs.

Car Brands: 
Aston Martin, Bentley, Ferrari, Lamborghini, Maserati, McLaren, Rolls-Royce
Alfa Romeo, Audi, BMW, Cadillac, Jaguar, Land Rover, Lexus, Mercedes-Benz, Porsche, Volvo
Abarth, Chrysler, Cupra, Dodge, DS AUTOMOBILES, Infiniti, Lotus, MINI, Morgan, Peugeot, Volkswagen
Chevrolet, Citroen, Fiat, Ford, Honda, Hummer, Hyundai, Jeep, Kia, Mazda, Nissan, Renault, SEAT, SKODA, Subaru, Toyota, Vauxhall
Aixam, Austin, Caterham, Dacia, Daewoo, Daihatsu, Daimler, Isuzu, Lancia, London Taxis International, MG, Mitsubishi, Perodua, Proton, Rover, Saab, Smart, Ssangyong, Suzuki, TVR


```{r}
unique_brands_luxury <- all_car_adverts %>%
  select(make, luxury_level) %>%    # Select only relevant columns
  distinct() %>%                    # Get unique combinations
  arrange(desc(luxury_level), make) # Sort by luxury level (descending) and brand name

# View the result
unique_brands_luxury

```
## Linear Model using all variables

```{r}
set.seed(5462)

# Stratified sampling to ensure `luxury_level` distribution remains similar
sample_index <- createDataPartition(all_car_adverts$luxury_level, p = 35000 / nrow(all_car_adverts), list = FALSE)

# Sample 10,000 rows from dataset
sample_data <- all_car_adverts[sample_index, ]

# Split the data: 70% Train, 15% Validation, 15% Test
train_index <- createDataPartition(sample_data$luxury_level, p = 0.7, list = FALSE)
train_data <- sample_data[train_index, ]
remaining_data <- sample_data[-train_index, ]

val_index <- createDataPartition(remaining_data$luxury_level, p = 0.5, list = FALSE)
validation_data <- remaining_data[val_index, ]
test_data <- remaining_data[-val_index, ]

```


```{r}
excluded_predictors <- c("car_price", "log_price","model","make","variant", "body_type","reg")
train_val_data <- bind_rows(train_data, validation_data)
predictors <- setdiff(names(train_val_data), excluded_predictors)

# Create formula dynamically
lm_formula <- as.formula(paste("log_price ~", paste(predictors, collapse = " + ")))

# Fit the linear regression model
lm_model <- lm(lm_formula, data = train_val_data)

# View model summary
summary(lm_model)


# Model Evaluation on Test Set
# Predict on test set
lm_preds <- predict(lm_model, newdata = test_data)

# Convert predictions back to original scale
lm_preds_original_scale <- exp(lm_preds)
y_true_original_scale <- exp(test_data$log_price)

# Calculate MSE and R²
lm_mse <- mean((y_true_original_scale - lm_preds_original_scale)^2)
lm_r2 <- cor(y_true_original_scale, lm_preds_original_scale)^2

# Output results
cat("\nLinear Regression (lm) Performance on Test Set:\n")
cat("Test MSE:", round(lm_mse, 2), "\n")
cat("Test R²:", round(lm_r2, 4), "\n")

```



## Best Subset Selection using Cross Validation
```{r}
set.seed(5462)

# Stratified sampling to ensure `luxury_level` distribution remains similar
sample_index <- createDataPartition(all_car_adverts$luxury_level, p = 35000 / nrow(all_car_adverts), list = FALSE)

# Sample 10,000 rows from dataset
sample_data <- all_car_adverts[sample_index, ]

# Split the data: 70% Train, 15% Validation, 15% Test
train_index <- createDataPartition(sample_data$luxury_level, p = 0.7, list = FALSE)
train_data <- sample_data[train_index, ]
remaining_data <- sample_data[-train_index, ]

val_index <- createDataPartition(remaining_data$luxury_level, p = 0.5, list = FALSE)
validation_data <- remaining_data[val_index, ]
test_data <- remaining_data[-val_index, ]

```


```{r}
# Load the function to generate formulas
source("generate_formulas.R")

# Function to generate all combinations of predictors
generate_formulas <- function(p, x_vars, y_var) {
  apply(combn(x_vars, p), 2, function(vars) {
    paste0(y_var, " ~ ", paste(vars, collapse = " + "))
  })
}

# Define target and predictor variables
target_var <- "log_price"
excluded_predictors <- c("car_price", "log_price", "make", "model", "variant","reg","body_type")
predictors <- setdiff(names(train_data), excluded_predictors)

# Generate formulas with 3 to 10 predictors 
predictor_range <- 3:10
```


```{r}

# Cross-Validation Function
evaluate_formula_cv <- function(formula_str, dataset, k = 5) {
  formula_obj <- as.formula(formula_str)
  n_samples <- nrow(dataset)
  select_vec <- rep(1:k, length.out = n_samples)
  data_split <- dataset %>% mutate(folds = sample(select_vec))
  
  mses <- numeric(k)
  r2s <- numeric(k)
  
  for (i in seq_len(k)) {
    data_train <- data_split %>% filter(folds != i)
    data_valid <- data_split %>% filter(folds == i)

    # Align factor levels
    factor_cols <- names(Filter(is.factor, data_train))
    data_valid <- data_valid %>% 
      mutate(across(all_of(factor_cols), ~ factor(.x, levels = levels(data_train[[cur_column()]]))))

    # Train and predict
    model <- lm(formula_obj, data = data_train)
    preds <- predict(model, newdata = data_valid)
    
    y_true <- data_valid[[as.character(formula_obj)[2]]]
    mses[i] <- mean((y_true - preds)^2)
    r2s[i] <- cor(y_true, preds)^2
  }
  
  list(mean_mse = mean(mses), mean_r2 = mean(r2s))
}
```


```{r}
# Evaluate All Formulas with CV
# Note: This part might take around 10 minutes

formula_results_cv <- data.frame(
  predictors_count = integer(),
  formula = character(),
  cv_mse = numeric(),
  cv_r2 = numeric(),
  stringsAsFactors = FALSE
)

for (p in predictor_range) {
  formulas <- generate_formulas(p = p, x_vars = predictors, y_var = target_var)

  for (formula_str in formulas) {
    metrics <- evaluate_formula_cv(formula_str, train_data, k = 5)

    formula_results_cv <- rbind(formula_results_cv, data.frame(
      predictors_count = p,
      formula = formula_str,
      cv_mse = metrics$mean_mse,
      cv_r2 = metrics$mean_r2
    ))
  }
}
```




```{r}
# -------------------------------------------
# Define weights for MSE and R²
# -------------------------------------------
alpha <- 0.45  # Weight for MSE
beta <- 0.45  # Weight for R²
gamma <- 0.1  # Penalty for the number of predictors

formula_results_cv <- formula_results_cv %>%
  mutate(combined_score = alpha * (cv_mse / max(cv_mse)) +
                        beta * (1 - (cv_r2 / max(cv_r2))) +
                        gamma * (predictors_count / max(predictors_count)))

# -------------------------------------------
# Select the Best Formula Based on Combined Score
# -------------------------------------------
best_combined_formula <- formula_results_cv %>%
  filter(combined_score == min(combined_score))

# -------------------------------------------
# Output the Best Formula and Scores
# -------------------------------------------
cat("\nBest formula based on combined MSE and R² score:\n")
cat("Formula:", best_combined_formula$formula, "\n")
cat("Mean CV MSE:", round(best_combined_formula$cv_mse, 4), "\n")
cat("Mean CV R²:", round(best_combined_formula$cv_r2, 4), "\n")
cat("Combined Score:", round(best_combined_formula$combined_score, 4), "\n")

# Convert the formula string to a formula object
best_formula_obj <- as.formula(best_combined_formula$formula)

# Train final model on train + validation data
train_val_data <- bind_rows(train_data, validation_data)
final_model <- lm(best_formula_obj, data = train_val_data)

# Evaluate on test set
test_preds <- predict(final_model, newdata = test_data)
subset_preds_original_scale <- exp(test_preds)
y_true_original_scale <- exp(test_data$log_price)

# Calculate test metrics
test_mse <- mean((y_true_original_scale - subset_preds_original_scale)^2)
test_r2 <- cor(y_true_original_scale, subset_preds_original_scale)^2

# Output test results
cat("\nFinal Model Performance on Test Set:\n")
cat("Test MSE:", round(test_mse, 2), "\n")
cat("Test R²:", round(test_r2, 4), "\n")


```
```{r}
# Select the best formula for each number of predictors
best_mse_by_predictors <- formula_results_cv %>%
  group_by(predictors_count) %>%
  slice_min(order_by = cv_mse, n = 1) %>%  # Selects the row with the minimum MSE
  ungroup()

# Plot MSE vs. Number of Predictors
ggplot(best_mse_by_predictors, aes(x = predictors_count, y = cv_mse)) +
  geom_line(color = "steelblue", size = 1.2) +
  geom_point(color = "red", size = 3) +
  labs(
    title = "Best MSE by Number of Predictors",
    x = "Number of Predictors",
    y = "Cross-Validated MSE"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    axis.title = element_text(size = 12)
  )

```

```{r}
rmse <- sqrt(158312930 )
rmse
```
```{r}
mean_price <- mean(all_car_adverts$car_price)
sd_price <- sd(all_car_adverts$car_price)

mean_price
sd_price
```
```{r}
baseline_mse <- mean((test_data$car_price - mean(train_data$car_price))^2)
baseline_rmse <- sqrt(baseline_mse)
baseline_rmse
```

```{r}
(baseline_rmse-rmse)/baseline_rmse
```


## Lasso with a Fixed Lambda


```{r}
set.seed(5462)
# Stratified sampling to ensure `luxury_level` distribution remains similar
sample_index <- createDataPartition(all_car_adverts$luxury_level, p = 35000 / nrow(all_car_adverts), list = FALSE)

# Sample 10,000 rows from dataset
sample_data <- all_car_adverts[sample_index, ]

train_index <- createDataPartition(all_car_adverts$luxury_level, p = 0.7, list = FALSE)
train_data <- all_car_adverts[train_index, ]
remaining_data <- all_car_adverts[-train_index, ]

val_index <- createDataPartition(remaining_data$luxury_level, p = 0.5, list = FALSE)
validation_data <- remaining_data[val_index, ]
test_data <- remaining_data[-val_index, ]

train_val_data <- bind_rows(train_data, validation_data)

# Define predictors (excluding target and unwanted variables)
excluded_predictors <- c("car_price", "log_price", "make", "model", "variant", "reg")
predictors <- setdiff(names(train_val_data), excluded_predictors)

# Convert predictors to matrix
x_train_val <- model.matrix(~ ., data = train_val_data[, predictors])[, -1]
y_train_val <- train_val_data$log_price

x_test <- model.matrix(~ ., data = test_data[, predictors])[, -1]
y_test <- test_data$log_price

# Train LASSO Model with fixed lambda
fixed_lambda <- 0.05
lasso_model <- glmnet(
  x_train_val, y_train_val,
  alpha = 1,                 # LASSO
  lambda = fixed_lambda,
  standardize = TRUE
)

# Predict and evaluate
lasso_preds <- predict(lasso_model, newx = x_test)
mse_lasso <- mean((y_test - lasso_preds)^2)
cat("LASSO Test MSE:", round(mse_lasso, 4), "\n")

# Exponentiate actual and predicted values to original scale
y_test_original <- exp(y_test)
lasso_preds_original <- exp(lasso_preds)

# Calculate MSE in original scale
mse_lasso_original <- mean((y_test_original - lasso_preds_original)^2)
cat("LASSO Test MSE (Original Scale):", round(mse_lasso_original, 2), "\n")

# Calculate RMSE (for interpretability in price units)
rmse_lasso_original <- sqrt(mse_lasso_original)
cat("LASSO Test RMSE (Original Scale):", round(rmse_lasso_original, 2), "\n")
```

## Lasso with cross validated Lambda

```{r}
 library(glmnet)

# ✅ Perform LASSO with cross-validation (default k=10 folds)
set.seed(5462)  # Ensures reproducibility
cv_lasso_model <- cv.glmnet(
  x_train_val, y_train_val,
  alpha = 1,                # LASSO (L1 regularization)
  standardize = TRUE,       # Standardize predictors
  nfolds = 10               # Number of cross-validation folds
)

# ✅ Optimal lambda values
best_lambda <- cv_lasso_model$lambda.min       # Lambda with minimum MSE
lambda_1se <- cv_lasso_model$lambda.1se        # More regularized (simpler) model

cat("✅ Best Lambda (Min MSE):", round(best_lambda, 5), "\n")
cat("✅ Lambda (1-SE Rule):", round(lambda_1se, 5), "\n")

# ✅ Predict using the best lambda (lambda.min)
lasso_cv_preds_min <- predict(cv_lasso_model, s = best_lambda, newx = x_test)
mse_lasso_min <- mean((y_test - lasso_cv_preds_min)^2)
cat("✅ LASSO CV Test MSE (lambda.min):", round(mse_lasso_min, 4), "\n")

# ✅ Predict using the 1-SE lambda (lambda.1se)
lasso_cv_preds_1se <- predict(cv_lasso_model, s = lambda_1se, newx = x_test)
mse_lasso_1se <- mean((y_test - lasso_cv_preds_1se)^2)
cat("✅ LASSO CV Test MSE (lambda.1se):", round(mse_lasso_1se, 4), "\n")


# ✅ Convert predictions and true values back to original scale
y_test_original <- exp(y_test)
lasso_preds_min_original <- exp(lasso_cv_preds_min)
lasso_preds_1se_original <- exp(lasso_cv_preds_1se)

# ✅ Calculate MSE and RMSE on the original scale
mse_min_original <- mean((y_test_original - lasso_preds_min_original)^2)
rmse_min_original <- sqrt(mse_min_original)

mse_1se_original <- mean((y_test_original - lasso_preds_1se_original)^2)
rmse_1se_original <- sqrt(mse_1se_original)

cat("✅ LASSO CV Test MSE (Original Scale, lambda.min):", round(mse_min_original, 2), "\n")
cat("✅ LASSO CV Test RMSE (Original Scale, lambda.min):", round(rmse_min_original, 2), "\n")

cat("✅ LASSO CV Test MSE (Original Scale, lambda.1se):", round(mse_1se_original, 2), "\n")
cat("✅ LASSO CV Test RMSE (Original Scale, lambda.1se):", round(rmse_1se_original, 2), "\n")

```
## Comparison


```{r}
# ✅ Predictions (in original scale)
lm_preds_original_scale                  # OLS predictions
subset_preds_original_scale              # Best Subset predictions
lasso_preds_original   # LASSO with fixed lambda predictions
lasso_preds_min_original        # LASSO with CV-selected lambda predictions

# ✅ True values in original scale
y_test_original <- exp(y_test)

# ✅ Calculate MSEs
mse_ols <- mean((y_test_original - lm_preds_original_scale)^2)
mse_subset <- mean((y_test_original - subset_preds_original_scale)^2)
mse_lasso_fixed <- mean((y_test_original - lasso_preds_original)^2)
mse_lasso_cv <- mean((y_test_original - lasso_preds_min_original)^2)


```

```{r}
library(ggplot2)
library(tibble)
library(dplyr)

# ✅ Create a data frame with MSE values
mse_results <- tibble(
  Method = c("LM", "Best Subset", "LASSO (Fixed λ)", "LASSO (CV λ)"),
  MSE = c(mse_ols, mse_subset, mse_lasso_fixed, mse_lasso_cv)
)

```

```{r}
# ✅ Plot the comparison
ggplot(mse_results, aes(x = Method, y = MSE, fill = Method)) +
  geom_bar(stat = "identity", color = "black", width = 0.7) +
  geom_text(aes(label = round(MSE, 0)), vjust = -0.5, size = 4) +  # Add MSE values above bars
  labs(
    title = "✅ Comparison of Test Set MSE (Original Car Price Scale)",
    x = "Model",
    y = "Test MSE"
  ) +
  theme_minimal() +
  theme(
    legend.position = "none",
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5)
  ) +
  scale_fill_viridis_d()

```






